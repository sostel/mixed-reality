---
layout: LandingPage
title: Mixed Reality Dev Days Sessions
description: Learn to build mixed reality experiences for HoloLens and immersive headsets.
author: jessemcculloch 
ms.author: jemccull
ms.date: 04/16/2019
ms.topic: article
keywords: Mixed Reality, conference, summit, developer, HoloLens, HoloLens 2, Kinect
---

# Mixed Reality Dev Days - Sessions

The following is a list of *SOME* of the currently scheduled sessions.  **_This list is subject to change_**

| **Session Title** | **Speaker(s) Name(s)** | **Session Description** |
| ----------------- | ---------------------- | --------------------- |
| Azure Mixed Reality Services: Overview & Roadmap | Neena Kamath, Jonathan Lyons | In this session, we'll share how developers and businesses can build spatially aware apps using new mixed reality cloud services like Azure Spatial Anchors, Azure Digital Twins and Azure Remote Rendering. The services we’re introducing are designed for the needs of modern applications and businesses: contextual insights driven by connected places, people and devices; collaboration powered by cross-platform development tools; and decisions fueled by high-polygon, interactive 3D content. We'll share our vision, industry momentum, common customer scenarios, and how you can start building or enhancing your own mixed reality applications today. |
| Intro to Developing for Azure Kinect | Erica Towle | Azure Kinect provides developers access to the best AI sensors in one convenient device. In this session, we will show the steps needed to get started developing on this new platform, how to take existing Kinect for Windows applications and enable them to use Azure Kinect, and show how you can use Azure Kinect with Windows containers to enable easy integration with Azure services. |
| Getting Started with MRTK v2 | Yoyo Zhang | From construction sites to factory floors, from operating rooms to classrooms, mixed reality is changing how we work, learn, communicate and get things done. This session is designed to introduce Mixed Reality to  those interested in learning more about what it means to go from a 2D to a 3D-world, the total addressable market for mixed reality, the real-world use. |
| Input and Interaction Crash Course - Articulated Hands | Julia Schwarz | We will go over lessons learned and interaction design tips for Hololens 2, focusing on hand interactions. |
| Why multi-user experiences are so hard | Graham Bury | Let's have a discussion on what we've learned over the past year on building shared experiences.  We will discuss through design considerations, what we've heard from customers and partners, talk about various tech and services under consideration, and how we envision providing interfaces in our tools to help with multi-user app development.  There are various options and paths, so we'd love to hear feedback with Q/A. |
| OpenXR on HoloLens 2: Standardizing mixed reality development | Alex Turner | OpenXR 1.0 is almost here! Are you building mixed reality support into your own engine or native app from the ground up? If so, learn about the key details of the OpenXR native API surface, including the extensions that will bring along the full feature set of HoloLens 2. With OpenXR, you can build cross-vendor mixed reality engines and native apps that span the breadth of devices in the industry! |
| Input and Interaction Crash Course - Eye Tracking | Sophie Stellmach | Want to bring magic to your customers? Join us to learn about one of the amazing new capabilities on HoloLens 2: Eye Tracking! After a brief overview of Eye Tracking and the immense potential this has for Mixed Reality, we will provide a hands-on walkthrough of how YOU can get started to bring Eye Tracking into your apps in Unity MRTK. |
| Azure Digital Twins + HoloLens: Powering the Next Generation of IoT | Will Guyman, Matt Vogel | Your app canvas is no longer limited to a 2D environment; the world in now your app canvas, backed by spatial intelligence from things like IoT sensors, mixed reality, and computer vision.  So, what now, and what’s next? In this session, you’ll learn how IoT and mixed reality are driving innovation and business impact in real industry scenarios like manufacturing and AEC.  We’ll cover why spatial intelligence is valuable and beneficial to your apps and market, problems and solutions from customers, and the tools and architectures to keep in mind when build spatially intelligent apps. |
| Developing Mobile Augmented Reality (AR) Applications with Azure Spatial Anchors | Paris Morgan, Rene Shulte | Azure Spatial Anchors is a mixed reality cloud service that makes it easier to build spatially aware, enterprise ready, cross-platform applications for AR across HoloLens, iOS and Android devices. This session walks through how to develop a cross-platform mobile AR application for iOS and Android devices. We’ll cover how to use native mobile tools, middleware, and Azure Spatial Anchors to build AR experiences people love. Join this session to dive deep into a specific application scenario, learn best practices, how to avoid common pitfalls, and how the cloud can accelerate your development and innovation. |
| Augmenting HoloLens interactions with Cognitive Services Speech SDK for Unity | Hakon Strande, Alex Thaman, Nick Landry, Others | Voice is an important interaction method for Mixed Reality applications, from command & control to natural language interactions with AI assistants. When the user's hands are occupied with tools and handling real objects, the ability to use voice to interact with the application allows UI and application action control while keeping hands and focus on the task. </br> In this session we will show you the benefit of the Azure speech services in terms of Command & Control, Dictation, Translation, Transcription, and the Intelligent Agent, using examples to show how these features can transform the utility of your application and free your users from the yoke of constant hand gestures when beneficial to completion of modern worker tasks. Through sample code and demos we will walk through the features of the Unity plugin for the Azure Speech SDK, showing performance, reliability and intent recognition benefits. |
| Connect the World - Remove the Language Barrier | Chris Wendt | Explore the translation capabilities of Azure Cognitive Services. The Translator Text API provides automatic translation of text between 60 languages, any to any. The Speech service translates from 11 spoken languages to more than 60 other languages. AI-based customization adapts to your enterprise's preferred terminology and style, you can drive all that through an API, from your own app, or use the Microsoft-provided web portal to do this. You can connect speakers of different languages, on their own devices, via the Translator Live functionality. All of this in a certified compliant and confidentiality-protecting environment. |
| Prototyping MR with Maquette | Dan Newell | |
| Developing with AltSpace SDK | Soren Hannibal Nielsen, Eric Anderson | |
| Intro to Developing for WebVR/XR with Babylon.js | Saurabh Bhatia, Jason Carter | |
| Maps for Mixed Reality | Jesse Levine, Brian Kircher, David Buerer | Introduction to the new Maps SDK for Unity. This SDK provides a control to visualize a 3D map in Unity. The map control handles streaming and rendering of 3D terrain data with world-wide coverage. Select cities are rendered at a very high level of detail. This session will cover getting started with the SDK, integration with MRTK, and the SDK implementation. |
| Project Acoustics - Fast and accurate physics based acoustics | Hakon Strande | Projects acoustics does for audio design, what baked physically-based lighting did for graphics”, using Azure cloud power. Do you want to spend your time designing sounds instead of faking the physics of sound wave propagation? Do you find tuning complex spatial sound environments costly, time consuming, and unfeasible to achieve the results you want? </br> Project Acoustics solves these problems and saves you time. Project Acoustics is a codeless wave physics-based system that – while maintaining designer control and freedom - calculates acoustic parameters for wave propagation effects like portalling, reverb, occlusion and obstruction based on the materials and geometry of your virtual world. Design your acoustics from that detailed starting point without placing reverb volumes or casting rays. Apply the results in microseconds at runtime. Learn how to use this system to improve acoustic quality and save time today |
| From the Trenches - Tips & Tricks from Dynamics 365 MR developers | Ricky Roesler | Join the Mixed Reality and Perception Business Applications group as we share our best tips and tricks to master MR application development. Our team has years of experience building applications on HoloLens and Windows Mixed Reality headsets. This session will cover technical topics around performance and graphical presentation, as well as design considerations around input and UX. We will also cover what to consider with the new features of HoloLens 2. |
| Hololens V1 to V2 Porting Guide: What we've learned from early ISV porting | Kevin Collins | |
| Developing for Windows Mixed Reailty VR | Dan Newell / May Ji | |
| Increasing Immersion with the MR Lighting Tools | Nick Klingensmith | To-date, most 3D graphics have been rendered on opaque displays. Now, not only are we putting holograms into the real world, but we're also doing it on additive displays! How do we render holograms that look good in this environment, and how do we make them look like they belong? The Mixed Reality Lighting Tools are a collection of easy Unity based solutions, from replicating your environment's lighting, to casting believable additive shadows. Come find out how easy it is to make your Mixed Reality application more immersive! |
| HoloLens 2 Practical Porting Experience Sharing | Heather Raikes, Forrest Trepte, Todd Williams | We will share learnings and best practices from two experiences we’re porting from HoloLens 1 to HoloLens 2: Galaxy Explorer and the Contoso Heights Tower Demo. The session will cover design process, prototypes, engineering foundations, using MRTK 2, key takeaways and lessons learned.|
| Delivering solutions with Dynamics 365 MR Biz Apps | Ester Barbuto | |
| Azure IOT & Azure Sphere Overview | Olivia Burgess/Tony Shakib | |
| Target markets and business opportuinty for Hololens 2 | Matt Fleckenstein | |
| Intro to Body Tracking on Azure Kinect | Quentin Miller | Microsoft has developed a new Body Tracking SDK from the ground up. Come and learn about this new SDK. You will get an overview of the SDK and a walk-through of how we developed a jump analysis tool using the SDK. You will leave ready to build your own amazing applications that rely on our new Azure Kinect body tracking technology. |
| Intro to Microsoft Co-sell: activating the Microsoft scale engine for your company | Andrea Houchens | |
